{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "mount_file_id": "https://github.com/nipun-taneja/amorphous-yolo/blob/main/notebooks/01_baseline_vs_eiou.ipynb",
      "authorship_tag": "ABX9TyO/UAQ2JPQ5Mo9cezOYrC4m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nipun-taneja/amorphous-yolo/blob/main/notebooks/01_baseline_vs_eiou.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Code"
      ],
      "metadata": {
        "id": "1UxEr6MRIBZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install -U \"ultralytics\" \"wandb\"\n",
        "!pip install roboflow\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "A38L7TDK1JjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "fdVoljtoksm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HNTrWtaNksGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eiRVNK3p024h",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Clone your repo into the Colab VM\n",
        "!git clone https://github.com/nipun-taneja/amorphous-yolo.git\n",
        "%cd amorphous-yolo\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()  # will show a link; paste your API key from wandb.ai"
      ],
      "metadata": {
        "id": "fC8i0AFG1frK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_DIR = \"/content/amorphous-yolo\"\n",
        "DRIVE_PROJECT_DIR = \"/content/drive/MyDrive/amorphous-yolo\"\n",
        "DATASETS = [\"coco8\",\"DUO_dataset\",\"trashcan\"]\n"
      ],
      "metadata": {
        "id": "pD--gfmyG53B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cp -r \"/content/drive/MyDrive/amorphous-yolo/datasets\" \"/content/amorphous-yolo\""
      ],
      "metadata": {
        "id": "VV3nvLsdH_OU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## View Ultralytics YOLO Bounding Box Code"
      ],
      "metadata": {
        "id": "76PZFuAHIo4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect, ultralytics\n",
        "from ultralytics.utils import loss as loss_mod\n",
        "\n",
        "print(\"Ultralytics version:\", ultralytics.__version__)\n",
        "print(loss_mod.BboxLoss)\n",
        "print(inspect.getsource(loss_mod.BboxLoss.forward)[:2500])\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "54JTduPP4PlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking if custom loss defined is working"
      ],
      "metadata": {
        "id": "9EtwAQ8iJBaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from src.losses import EIoULoss, AEIoULoss\n",
        "import torch\n",
        "\n",
        "print(\"Ultralytics version:\", __import__(\"ultralytics\").__version__)\n",
        "\n",
        "loss_fn = EIoULoss()\n",
        "loss_fn_A = AEIoULoss()\n",
        "\n",
        "pred = torch.tensor([[0.0, 0.0, 1.0, 1.0],\n",
        "                     [0.2, 0.2, 0.8, 0.8]])\n",
        "gt   = torch.tensor([[0.0, 0.0, 1.0, 1.0],\n",
        "                     [0.0, 0.0, 1.0, 1.0]])\n",
        "\n",
        "print(\"EIoU placeholder loss:\", loss_fn(pred, gt).item())\n",
        "print(\"AEIoU placeholder loss:\", loss_fn_A(pred, gt).item())"
      ],
      "metadata": {
        "id": "Ih4NUtkJ4V_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## updating runs in drive"
      ],
      "metadata": {
        "id": "ZuXfYzEdW9U9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p \"/content/drive/MyDrive/amorphous-yolo\"\n",
        "!cp -r /content/amorphous-yolo/amorphous-yolo/* \"/content/drive/MyDrive/amorphous-yolo\""
      ],
      "metadata": {
        "id": "hecklEA6M04N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p \"/content/drive/MyDrive/checkpoints/amorphous-yolo\"\n",
        "\n",
        "!cp -r /content/amorphous-yolo/amorphous-yolo/runs/detect/experiments/baseline_your_dataset \\\n",
        "      \"/content/drive/MyDrive/checkpoints/amorphous-yolo/\"\n"
      ],
      "metadata": {
        "id": "HXu-016eP-Er"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## YOLOv8 Training Basic (COCO8)\n",
        "\n",
        "This script demonstrates how to train a YOLO model using the **Ultralytics YOLO API** on the lightweight **COCO8** dataset. It is intended for quick experimentation and validation of the training pipeline.\n"
      ],
      "metadata": {
        "id": "n1mPrlLdJPrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"yolo26n.pt\")  # works with 8.4.9 as you saw\n",
        "results = model.train(\n",
        "    data=\"coco8.yaml\",\n",
        "    epochs=3,\n",
        "    imgsz=640,\n",
        "    project=Path(PROJECT_DIR) /\"experiments\",\n",
        "    name=\"coco_yolo26n_baseline_e3\",\n",
        "    device=0,\n",
        ")\n",
        "print(results)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "aCEN3kdL4fCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting data from Roboflow.\n",
        "We already have duo dataset downloaded, no need to re download"
      ],
      "metadata": {
        "id": "Fyr7ft2v5MiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "ROBOFLOW_API_KEY = userdata.get('ROBOFLOW')\n"
      ],
      "metadata": {
        "id": "0IDRLAHCJtmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
        "project = rf.workspace(\"amorphousyolo\").project(\"duo-dataset-ofte9\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolo26\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "gVI4LM7c5Lvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check if DUO data is correctly accessible"
      ],
      "metadata": {
        "id": "Y3QDco4DN69-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = Path(PROJECT_DIR) / \"datasets\" / DATASETS[1] / \"train/images\"\n",
        "label_dir = Path(PROJECT_DIR) / \"datasets\" / DATASETS[1] / \"train/labels\""
      ],
      "metadata": {
        "id": "Igca1c5dRqdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dir)\n",
        "# /content/amorphous-yolo/datasets/DUO_dataset/train/images"
      ],
      "metadata": {
        "id": "nymi_v1dVeaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This utility function randomly samples images from a dataset and overlays\n",
        "# their corresponding **YOLO-format bounding boxes** for quick visual inspection\n",
        "#  useful for sanity-checking labels before training.\n",
        "import random, cv2, matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "def show_random(img_root, lbl_root, n=20):\n",
        "    img_paths = list(Path(img_root).glob(\"*.jpg\"))\n",
        "    random.shuffle(img_paths)\n",
        "\n",
        "    for img_path in img_paths[:n]:\n",
        "        img = cv2.imread(str(img_path))\n",
        "        h, w = img.shape[:2]\n",
        "        label_path = Path(lbl_root) / (img_path.stem + \".txt\")\n",
        "\n",
        "        if label_path.exists():\n",
        "            with open(label_path) as f:\n",
        "                for line in f:\n",
        "                    parts = line.strip().split()\n",
        "                    if len(parts) < 5:\n",
        "                        continue  # skip malformed\n",
        "                    cls = int(parts[0])\n",
        "                    x_c, y_c, bw, bh = map(float, parts[1:5])  # ignore extra values\n",
        "\n",
        "                    x_c *= w; y_c *= h; bw *= w; bh *= h\n",
        "                    x1, y1 = int(x_c - bw/2), int(y_c - bh/2)\n",
        "                    x2, y2 = int(x_c + bw/2), int(y_c + bh/2)\n",
        "                    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "        plt.figure(figsize=(4, 4))\n",
        "        plt.title(img_path.name)\n",
        "        plt.axis(\"off\")\n",
        "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "g9kII_1bZSJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "imgs = list(train_dir.glob(\"*\"))\n",
        "print(len(imgs), \"files\")\n",
        "print(imgs[:5])\n",
        "\n",
        "show_random(\n",
        "    img_root=train_dir,\n",
        "    lbl_root=label_dir,\n",
        "    n=5,\n",
        ")"
      ],
      "metadata": {
        "id": "kAIr78VlZ0iz",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This script is a **low-level debugging utility** for verifying that a specific\n",
        "#  image and its corresponding YOLO label file exist, are readable, and align\n",
        "#  correctly when rendered. It is ideal for diagnosing dataset issues such as\n",
        "# missing labels, malformed annotations, or incorrect paths.\n",
        "import cv2, matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "img_path = train_dir / \"4828_jpg.rf.9e0a7e8d443c379bf491e4b866b5a524.jpg\"\n",
        "label_path = label_dir / (img_path.stem + \".txt\")\n",
        "\n",
        "print(\"Image exists:\", img_path.exists())\n",
        "print(\"Label path:\", label_path)\n",
        "print(\"Label exists:\", label_path.exists())\n",
        "if label_path.exists():\n",
        "    print(\"Label contents (first 5 lines):\")\n",
        "    with open(label_path) as f:\n",
        "        for i, line in enumerate(f):\n",
        "            print(\" \", line.strip())\n",
        "            if i == 4:\n",
        "                break\n",
        "\n",
        "img = cv2.imread(str(img_path))\n",
        "h, w = img.shape[:2]\n",
        "\n",
        "if label_path.exists():\n",
        "    with open(label_path) as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) < 5:\n",
        "                continue\n",
        "            cls = int(parts[0])\n",
        "            x_c, y_c, bw, bh = map(float, parts[1:5])\n",
        "            x_c *= w; y_c *= h; bw *= w; bh *= h\n",
        "            x1, y1 = int(x_c - bw/2), int(y_c - bh/2)\n",
        "            x2, y2 = int(x_c + bw/2), int(y_c + bh/2)\n",
        "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "plt.figure(figsize=(4,4))\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "E8fMcj_4aOAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This utility visualizes **polygon-based YOLO annotations** (segmentation format)\n",
        "# by randomly sampling images and drawing a **bounding box derived from polygon\n",
        "# extents**. It’s useful for validating segmentation labels and quickly\n",
        "# spotting malformed or mis-scaled polygons.\n",
        "import random, cv2, matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "def show_random_poly(img_root, lbl_root, n=5):\n",
        "    img_paths = list(Path(img_root).glob(\"*.jpg\"))\n",
        "    random.shuffle(img_paths)\n",
        "\n",
        "    for img_path in img_paths[:n]:\n",
        "        img = cv2.imread(str(img_path))\n",
        "        h, w = img.shape[:2]\n",
        "        label_path = Path(lbl_root) / (img_path.stem + \".txt\")\n",
        "        print(\"Image:\", img_path.name, \"Label exists:\", label_path.exists())\n",
        "\n",
        "        if label_path.exists():\n",
        "            with open(label_path) as f:\n",
        "                for line in f:\n",
        "                    parts = line.strip().split()\n",
        "                    if len(parts) < 3:\n",
        "                        continue\n",
        "                    cls = int(parts[0])\n",
        "                    coords = list(map(float, parts[1:]))\n",
        "\n",
        "                    xs = np.array(coords[0::2]) * w\n",
        "                    ys = np.array(coords[1::2]) * h\n",
        "\n",
        "                    x1, x2 = int(xs.min()), int(xs.max())\n",
        "                    y1, y2 = int(ys.min()), int(ys.max())\n",
        "                    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "        plt.figure(figsize=(4, 4))\n",
        "        plt.title(img_path.name)\n",
        "        plt.axis(\"off\")\n",
        "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "        plt.show()\n",
        "\n",
        "show_random_poly(\n",
        "    img_root= train_dir,\n",
        "    lbl_root= label_dir,\n",
        "    n=5,\n",
        ")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "E7rOCc42aiez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Processing and getting trashcan data, dont repeat"
      ],
      "metadata": {
        "id": "SuEpeertdj0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "69hv5gzMtu5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/amorphous-yolo/data/dataset.zip /content/amorphous-yolo/amorphous-yolo/datasets/trashcan.zip"
      ],
      "metadata": {
        "id": "XBE_p8zUtvqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/datasets/trashcan_raw"
      ],
      "metadata": {
        "id": "qoZw_VshwLJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/amorphous-yolo/amorphous-yolo/datasets"
      ],
      "metadata": {
        "id": "nCKsn-1gwaht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/amorphous-yolo/amorphous-yolo/datasets/trashcan.zip"
      ],
      "metadata": {
        "id": "7MIEiZIDwcN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls  /content/amorphous-yolo/amorphous-yolo/datasets/trashcan-raw\n"
      ],
      "metadata": {
        "id": "Y2EKGKhUx4Nw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tree /content/amorphous-yolo/amorphous-yolo/datasets/trashcan-raw"
      ],
      "metadata": {
        "id": "F18bSZfJ60WL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "ROOT = Path(\"/content/amorphous-yolo/amorphous-yolo/datasets/trashcan-raw\")\n",
        "print(\"instance_version/train files:\", len(list((ROOT/\"instance_version/train\").glob(\"*\"))))\n",
        "print(\"instance_version/val files:\", len(list((ROOT/\"instance_version/val\").glob(\"*\"))))\n",
        "print(\"original_data/images files:\", len(list((ROOT/\"original_data/images\").glob(\"*.jpg\"))))\n"
      ],
      "metadata": {
        "id": "nk8TPn7t7E7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycocotools -q\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "from pycocotools.coco import COCO\n",
        "\n",
        "ROOT = Path(\"/content/amorphous-yolo/amorphous-yolo/datasets/trashcan-raw\")\n",
        "INSTANCE_DIR = ROOT / \"instance_version\"\n",
        "IMAGES_DIR = ROOT / \"original_data\" / \"images\"\n",
        "\n",
        "OUT_ROOT = Path(\"/content/amorphous-yolo/amorphous-yolo/datasets/trashcan\")\n",
        "IMG_TRAIN_DIR = OUT_ROOT / \"images\" / \"train\"\n",
        "IMG_VAL_DIR   = OUT_ROOT / \"images\" / \"val\"\n",
        "LBL_TRAIN_DIR = OUT_ROOT / \"labels\" / \"train\"\n",
        "LBL_VAL_DIR   = OUT_ROOT / \"labels\" / \"val\"\n",
        "\n",
        "for d in [IMG_TRAIN_DIR, IMG_VAL_DIR, LBL_TRAIN_DIR, LBL_VAL_DIR]:\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def coco_to_yolo(json_name, split):\n",
        "    coco = COCO(str(INSTANCE_DIR / json_name))\n",
        "    img_id_to_info = coco.imgs\n",
        "    cat_id_to_idx = {cat_id: i for i, cat_id in enumerate(sorted(coco.cats.keys()))}\n",
        "    print(f\"{split}: {len(img_id_to_info)} images, {len(coco.anns)} anns\")\n",
        "\n",
        "    for img_id, info in img_id_to_info.items():\n",
        "        file_name = info[\"file_name\"]\n",
        "        width, height = info[\"width\"], info[\"height\"]\n",
        "\n",
        "        src_img_path = IMAGES_DIR / file_name\n",
        "        if split == \"train\":\n",
        "            out_img_path = IMG_TRAIN_DIR / file_name\n",
        "            out_lbl_path = LBL_TRAIN_DIR / (Path(file_name).stem + \".txt\")\n",
        "        else:\n",
        "            out_img_path = IMG_VAL_DIR / file_name\n",
        "            out_lbl_path = LBL_VAL_DIR / (Path(file_name).stem + \".txt\")\n",
        "\n",
        "        if not src_img_path.exists():\n",
        "            continue\n",
        "\n",
        "        if not out_img_path.exists():\n",
        "            os.system(f'cp \"{src_img_path}\" \"{out_img_path}\"')\n",
        "\n",
        "        ann_ids = coco.getAnnIds(imgIds=[img_id])\n",
        "        anns = coco.loadAnns(ann_ids)\n",
        "        lines = []\n",
        "        for ann in anns:\n",
        "            cat_id = ann[\"category_id\"]\n",
        "            cls = cat_id_to_idx[cat_id]\n",
        "\n",
        "            x_min, y_min, bw, bh = ann[\"bbox\"]  # COCO bbox\n",
        "            x_c = (x_min + bw / 2) / width\n",
        "            y_c = (y_min + bh / 2) / height\n",
        "            bw_n = bw / width\n",
        "            bh_n = bh / height\n",
        "\n",
        "            x_c = min(max(x_c, 0.0), 1.0)\n",
        "            y_c = min(max(y_c, 0.0), 1.0)\n",
        "            bw_n = min(max(bw_n, 0.0), 1.0)\n",
        "            bh_n = min(max(bh_n, 0.0), 1.0)\n",
        "\n",
        "            lines.append(f\"{cls} {x_c:.6f} {y_c:.6f} {bw_n:.6f} {bh_n:.6f}\")\n",
        "\n",
        "        if lines:\n",
        "            with open(out_lbl_path, \"w\") as f:\n",
        "                f.write(\"\\n\".join(lines))\n",
        "\n",
        "coco_to_yolo(\"instances_train_trashcan.json\", \"train\")\n",
        "coco_to_yolo(\"instances_val_trashcan.json\", \"val\")\n"
      ],
      "metadata": {
        "id": "hDuQqJF18mu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pycocotools.coco import COCO\n",
        "import yaml\n",
        "from pathlib import Path\n",
        "\n",
        "INSTANCE_DIR = Path(\"/content/amorphous-yolo/amorphous-yolo/datasets/trashcan-raw/instance_version\")\n",
        "OUT_ROOT = Path(\"/content/amorphous-yolo/amorphous-yolo/datasets/trashcan\")\n",
        "\n",
        "coco_train = COCO(str(INSTANCE_DIR / \"instances_train_trashcan.json\"))\n",
        "cats = coco_train.loadCats(coco_train.getCatIds())\n",
        "cats_sorted = sorted(cats, key=lambda c: c[\"id\"])\n",
        "names = {i: c[\"name\"] for i, c in enumerate(cats_sorted)}\n",
        "print(\"names:\", names)\n",
        "\n",
        "data_dir = Path(\"/content/amorphous-yolo/amorphous-yolo/data\")\n",
        "data_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "yaml_dict = {\n",
        "    \"path\": str(OUT_ROOT),\n",
        "    \"train\": \"images/train\",\n",
        "    \"val\": \"images/val\",\n",
        "    \"names\": names,\n",
        "}\n",
        "\n",
        "with open(data_dir / \"trashcan.yaml\", \"w\") as f:\n",
        "    yaml.safe_dump(yaml_dict, f, sort_keys=False)\n",
        "\n",
        "print((data_dir / \"trashcan.yaml\").read_text())\n"
      ],
      "metadata": {
        "id": "1pq65TW39HI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random, cv2, matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "def show_random_trashcan(img_root, lbl_root, n=10):\n",
        "    img_paths = list(Path(img_root).glob(\"*.jpg\"))\n",
        "    random.shuffle(img_paths)\n",
        "\n",
        "    for img_path in img_paths[:n]:\n",
        "        img = cv2.imread(str(img_path))\n",
        "        h, w = img.shape[:2]\n",
        "        label_path = Path(lbl_root) / (img_path.stem + \".txt\")\n",
        "        print(\"Image:\", img_path.name, \"Label exists:\", label_path.exists())\n",
        "\n",
        "        if label_path.exists():\n",
        "            for line in open(label_path):\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) < 5:\n",
        "                    continue\n",
        "                _, x_c, y_c, bw, bh = map(float, parts[:5])\n",
        "                x_c *= w; y_c *= h; bw *= w; bh *= h\n",
        "                x1, y1 = int(x_c - bw/2), int(y_c - bh/2)\n",
        "                x2, y2 = int(x_c + bw/2), int(y_c + bh/2)\n",
        "                cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "        plt.figure(figsize=(4,4))\n",
        "        plt.axis(\"off\")\n",
        "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "        plt.show()\n",
        "\n",
        "show_random_trashcan(\n",
        "    \"/content/amorphous-yolo/amorphous-yolo/datasets/trashcan/images/train\",\n",
        "    \"/content/amorphous-yolo/amorphous-yolo/datasets/trashcan/labels/train\",\n",
        "    n=10,\n",
        ")\n"
      ],
      "metadata": {
        "id": "g5HSTQB_-NOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# “Phase 2 – DUO baselines”"
      ],
      "metadata": {
        "id": "Y69knKYc-61-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " # DUO-CIOU baseline"
      ],
      "metadata": {
        "id": "7GPkB4LbAbCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"yolo26n.pt\")\n",
        "results = model.train(\n",
        "    data=Path(PROJECT_DIR) / \"data\" / \"duo.yaml\",   # DUO Dataset yaml\n",
        "    epochs=20,\n",
        "    imgsz=640,\n",
        "    project=Path(PROJECT_DIR) /\"experiments\",\n",
        "    name=\"duo_yolo26n_baseline_e20\",\n",
        "    device=0,\n",
        ")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "27BGRO2f7sgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Patching YOLO Bounding Box Loss to Use EIoU\n",
        "\n",
        "This script **monkey-patches Ultralytics YOLO’s internal bounding box loss** to replace the default **CIoU-based IoU loss** with a custom **EIoU (Extended IoU) loss**, while leaving the rest of the loss pipeline unchanged.\n",
        "\n",
        "This allows experimentation with alternative IoU formulations **without forking or modifying Ultralytics source code**.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "RJivqFEOZtl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import ultralytics\n",
        "from ultralytics.utils import loss as loss_mod\n",
        "from src.losses import EIoULoss  # the file you showed\n",
        "\n",
        "print(\"Ultralytics version:\", ultralytics.__version__)\n",
        "\n",
        "# Keep a handle to the original if you ever want to restore it\n",
        "OriginalBboxLossForward = loss_mod.BboxLoss.forward\n",
        "\n",
        "\n",
        "def bbox_loss_forward_eiou(\n",
        "    self,\n",
        "    pred_dist: torch.Tensor,\n",
        "    pred_bboxes: torch.Tensor,\n",
        "    anchor_points: torch.Tensor,\n",
        "    target_bboxes: torch.Tensor,\n",
        "    target_scores: torch.Tensor,\n",
        "    target_scores_sum: torch.Tensor,\n",
        "    fg_mask: torch.Tensor,\n",
        "    imgsz: torch.Tensor,\n",
        "    stride: torch.Tensor,\n",
        "):\n",
        "    # Same weighting as original CIoU branch\n",
        "    weight = target_scores.sum(-1)[fg_mask].unsqueeze(-1)\n",
        "\n",
        "    # EIoU per-box loss in xyxy\n",
        "    eiou_loss_fn = EIoULoss(reduction=\"none\")\n",
        "    eiou_loss = eiou_loss_fn(pred_bboxes[fg_mask], target_bboxes[fg_mask])  # shape [N]\n",
        "\n",
        "    # Match original pattern: (loss * weight).sum() / target_scores_sum\n",
        "    loss_iou = (eiou_loss.unsqueeze(-1) * weight).sum() / target_scores_sum\n",
        "\n",
        "    # DFL branch (unchanged from original BboxLoss.forward)\n",
        "    if self.dfl_loss:\n",
        "        target_ltrb = loss_mod.bbox2dist(anchor_points, target_bboxes, self.dfl_loss.reg_max - 1)\n",
        "        loss_dfl = self.dfl_loss(\n",
        "            pred_dist[fg_mask].view(-1, self.dfl_loss.reg_max),\n",
        "            target_ltrb[fg_mask],\n",
        "        ) * weight\n",
        "        loss_dfl = loss_dfl.sum() / target_scores_sum\n",
        "    else:\n",
        "        target_ltrb = loss_mod.bbox2dist(anchor_points, target_bboxes)\n",
        "        # normalize ltrb by image size\n",
        "        target_ltrb = target_ltrb * stride\n",
        "        target_ltrb[..., 0::2] /= imgsz[1]\n",
        "        target_ltrb[..., 1::2] /= imgsz[0]\n",
        "        pred_dist = pred_dist * stride\n",
        "        pred_dist[..., 0::2] /= imgsz[1]\n",
        "        pred_dist[..., 1::2] /= imgsz[0]\n",
        "        loss_dfl = (\n",
        "            torch.nn.functional.l1_loss(\n",
        "                pred_dist[fg_mask],\n",
        "                target_ltrb[fg_mask],\n",
        "                reduction=\"none\",\n",
        "            ).mean(-1, keepdim=True)\n",
        "            * weight\n",
        "        )\n",
        "        loss_dfl = loss_dfl.sum() / target_scores_sum\n",
        "\n",
        "    return loss_iou, loss_dfl\n",
        "\n",
        "\n",
        "# Apply the patch\n",
        "loss_mod.BboxLoss.forward = bbox_loss_forward_eiou\n",
        "print(\"Patched BboxLoss.forward to use EIoU.\")\n"
      ],
      "metadata": {
        "id": "TEWMygXzOwma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the same model as your CIoU baseline\n",
        "model = YOLO(\"yolo26n.pt\")\n",
        "\n",
        "results = model.train(\n",
        "    data=Path(PROJECT_DIR) / \"data\" / \"duo.yaml\",   # same DUO yaml as baseline\n",
        "    epochs=20,\n",
        "    imgsz=640,\n",
        "    project=Path(PROJECT_DIR) /\"experiments\",\n",
        "    name=\"duo_yolo26_eiou_e20\",      # new run name\n",
        "    device=0,\n",
        ")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "kGLPiI_EPZkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "from ultralytics.utils import loss as loss_mod\n",
        "\n",
        "print(inspect.getsource(loss_mod.BboxLoss.forward)[:2400])\n"
      ],
      "metadata": {
        "id": "NdBvXYR7rD5Z",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import ultralytics\n",
        "from ultralytics.utils import loss as loss_mod\n",
        "from src.losses_new import AEIoULoss  # new class above\n",
        "\n",
        "print(\"Ultralytics version:\", ultralytics.__version__)\n",
        "\n",
        "# Choose λ-rigidity here\n",
        "RIGIDITY = 1.0  # later change to 0.1 for A-EIoU \"amorphous mode\"\n",
        "\n",
        "OriginalBboxLossForward = loss_mod.BboxLoss.forward\n",
        "\n",
        "\n",
        "def bbox_loss_forward_aeiou(\n",
        "    self,\n",
        "    pred_dist: torch.Tensor,\n",
        "    pred_bboxes: torch.Tensor,\n",
        "    anchor_points: torch.Tensor,\n",
        "    target_bboxes: torch.Tensor,\n",
        "    target_scores: torch.Tensor,\n",
        "    target_scores_sum: torch.Tensor,\n",
        "    fg_mask: torch.Tensor,\n",
        "    imgsz: torch.Tensor,\n",
        "    stride: torch.Tensor,\n",
        "):\n",
        "    \"\"\"Compute A-EIoU and DFL losses for bounding boxes.\"\"\"\n",
        "    weight = target_scores.sum(-1)[fg_mask].unsqueeze(-1)\n",
        "\n",
        "    # A-EIoU per-box loss in xyxy\n",
        "    aeiou_loss_fn = AEIoULoss(rigidity=RIGIDITY, reduction=\"none\")\n",
        "    aeiou_loss = aeiou_loss_fn(pred_bboxes[fg_mask], target_bboxes[fg_mask])  # [N]\n",
        "\n",
        "    loss_iou = (aeiou_loss.unsqueeze(-1) * weight).sum() / target_scores_sum\n",
        "\n",
        "    # DFL branch unchanged from original\n",
        "    if self.dfl_loss:\n",
        "        target_ltrb = loss_mod.bbox2dist(anchor_points, target_bboxes, self.dfl_loss.reg_max - 1)\n",
        "        loss_dfl = self.dfl_loss(\n",
        "            pred_dist[fg_mask].view(-1, self.dfl_loss.reg_max),\n",
        "            target_ltrb[fg_mask],\n",
        "        ) * weight\n",
        "        loss_dfl = loss_dfl.sum() / target_scores_sum\n",
        "    else:\n",
        "        target_ltrb = loss_mod.bbox2dist(anchor_points, target_bboxes)\n",
        "        target_ltrb = target_ltrb * stride\n",
        "        target_ltrb[..., 0::2] /= imgsz[1]\n",
        "        target_ltrb[..., 1::2] /= imgsz[0]\n",
        "        pred_dist = pred_dist * stride\n",
        "        pred_dist[..., 0::2] /= imgsz[1]\n",
        "        pred_dist[..., 1::2] /= imgsz[0]\n",
        "        loss_dfl = (\n",
        "            torch.nn.functional.l1_loss(\n",
        "                pred_dist[fg_mask],\n",
        "                target_ltrb[fg_mask],\n",
        "                reduction=\"none\",\n",
        "            ).mean(-1, keepdim=True)\n",
        "            * weight\n",
        "        )\n",
        "        loss_dfl = loss_dfl.sum() / target_scores_sum\n",
        "\n",
        "    return loss_iou, loss_dfl\n",
        "\n",
        "\n",
        "loss_mod.BboxLoss.forward = bbox_loss_forward_aeiou\n",
        "print(f\"Patched BboxLoss.forward to use A-EIoU with rigidity={RIGIDITY}.\")\n"
      ],
      "metadata": {
        "id": "EShzPxzzrFFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from src.losses_new import AEIoULoss\n",
        "\n",
        "print(AEIoULoss.__init__)\n",
        "help(AEIoULoss)\n"
      ],
      "metadata": {
        "id": "Qc1ocaCYzhUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"yolo26n.pt\")\n",
        "results = model.train(\n",
        "    data=Path(PROJECT_DIR) / \"data\" / \"duo.yaml\",\n",
        "    epochs=20,\n",
        "    imgsz=640,\n",
        "    project=Path(PROJECT_DIR) /\"experiments\",\n",
        "    name=\"duo_yolo26_aeiou_r1_e20\",\n",
        "    device=0,\n",
        ")\n"
      ],
      "metadata": {
        "id": "JzgiR-LkyNUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RIGIDITY = 0.1\n"
      ],
      "metadata": {
        "id": "AKyFQygvyRqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO(\"yolo26n.pt\")\n",
        "results = model.train(\n",
        "    data=dataset.location + \"/data.yaml\",\n",
        "    epochs=20,\n",
        "    imgsz=640,\n",
        "    project=\"experiments\",\n",
        "    name=\"duo_yolo26_aeiou_r0p1_e20\",\n",
        "    device=0,\n",
        ")\n"
      ],
      "metadata": {
        "id": "o6f2PPT9yVOn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}